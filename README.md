# TTS Voice Fine-tuning Project

This repository contains scripts for fine-tuning Text-to-Speech (TTS) models using your own voice data.

## ğŸ“ Project Structure

```
TTS_finetune/
â”œâ”€â”€ ğŸ“‚ data/                           # Data-related folders
â”‚   â”œâ”€â”€ audio_with_transcript/         # Original audio and transcript files
â”‚   â”‚   â”œâ”€â”€ JRE_2223_episode/          # Joe Rogan Experience Episode 2223 audio data
â”‚   â”‚   â””â”€â”€ JRE_2281_episode/          # Joe Rogan Experience Episode 2281 audio data
â”‚   â””â”€â”€ dataset_merged/                # Merged training dataset
â”‚       â”œâ”€â”€ train/                     # Training set
â”‚       â”œâ”€â”€ validation/                # Validation set
â”‚       â”œâ”€â”€ test/                      # Test set
â”‚       â””â”€â”€ dataset_dict.json          # Dataset configuration file
â”œâ”€â”€ ğŸ“‚ models/                         # Model-related folders
â”‚   â”œâ”€â”€ base_models/                   # Base pre-trained models
â”‚   â”‚   â””â”€â”€ orpheus-3b-0.1-ft/         # Orpheus 3B base model
â”‚   â”œâ”€â”€ finetuned_v1.0_baseline/       # Fine-tuned model v1.0 baseline version
â”‚   â”œâ”€â”€ finetuned_v1.1_merged/         # Fine-tuned model v1.1 merged version
â”‚   â””â”€â”€ finetuned_v2.0_latest/         # Fine-tuned model v2.0 latest version
â”œâ”€â”€ ğŸ“‚ scripts/                        # Script files
â”‚   â”œâ”€â”€ dataset_processor.py           # Data processing script
â”‚   â”œâ”€â”€ transcript_merger.py           # Transcript merging script
â”‚   â”œâ”€â”€ inference_pipeline.py          # Inference pipeline
â”‚   â””â”€â”€ utils.py                       # Utility functions
â”œâ”€â”€ ğŸ“‚ configs/                        # Configuration files
â”‚   â””â”€â”€ training_config.yaml           # Training configuration file
â”œâ”€â”€ ğŸ“‚ logs/                           # Logs and experiment records
â”‚   â”œâ”€â”€ training.log                   # Training logs
â”‚   â”œâ”€â”€ wandb/                         # Weights & Biases experiment records
â”‚   â””â”€â”€ sample_output_v2.0.wav         # Generated audio sample
â”œâ”€â”€ ğŸ“‚ docs/                           # Documentation folder
â”‚   â””â”€â”€ PROJECT_GUIDE.md               # Project usage guide
â”œâ”€â”€ requirements.txt                   # Python dependencies
â””â”€â”€ README.md                          # Project documentation
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Prepare Data
```bash
python scripts/dataset_processor.py --input_dir data/audio_with_transcript --output_dir data/dataset_merged
python scripts/transcript_merger.py --input_dir data/audio_with_transcript --output_file data/merged_transcripts.json
```

### 3. Fine-tune Model
```bash
# Run training in background using TMUX
tmux new -d -s train WANDB_API_KEY=<your_key> accelerate launch --config_file accelerate_config.yaml train.py
```

### 4. Generate Speech
```bash
python scripts/inference_pipeline.py \
    --config configs/training_config.yaml \
    --model_path models/finetuned_v2.0_latest/checkpoint-3500 \
    --text "Hello, this is a test message" \
    --output_path logs/test_output.wav
```

## ğŸ“‹ Features

- âœ… Multi-language TTS fine-tuning support
- âœ… Weights & Biases experiment tracking integration
- âœ… Accelerate distributed training support
- âœ… Modular data processing pipeline
- âœ… Simplified inference interface

## ğŸ› ï¸ Technical Specifications

- **Base Model**: Orpheus 3B
- **Training Framework**: PyTorch + Transformers + Accelerate
- **Audio Processing**: LibROSA + SoundFile
- **Experiment Tracking**: Weights & Biases

## ğŸ“Š Model Versions

| Version | Folder Name | Description | Recommended Use |
|---------|-------------|-------------|-----------------|
| v1.0 | finetuned_v1.0_baseline | Baseline version | Experimental testing |
| v1.1 | finetuned_v1.1_merged | Merged version | Medium quality |
| v2.0 | finetuned_v2.0_latest | Latest version | Production use |

## ğŸ”§ System Requirements

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (GPU recommended)
- At least 16GB RAM
- At least 10GB available disk space

## ğŸ“ Notes

- Ensure audio quality is good with minimal background noise
- Recommend using at least 10-20 audio samples for fine-tuning
- Training time depends on hardware configuration
- Make sure to set appropriate WANDB API key

## ğŸ¤ Contributing

Issue reports and feature requests are welcome!

## ğŸ“š Documentation

For complete usage guide, please refer to: [Project Usage Guide](docs/PROJECT_GUIDE.md)

## ğŸ“„ License

This project is licensed under the MIT License. 