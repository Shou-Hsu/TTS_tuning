# TTS Voice Fine-tuning Project

This repository provides a recommended project structure and guidelines for fine-tuning Text-to-Speech (TTS) models using your own voice data.

## ğŸ“ Project Structure

```
TTS_finetune/
â”œâ”€â”€ ğŸ“‚ data/                           # Data-related folders
â”‚   â”œâ”€â”€ raw_data/                      # Original audio and transcript files
â”‚   â”‚   â”œâ”€â”€ example1/                  # Example: audio and transcipt data
â”‚   â”‚   â”‚   â”œâ”€â”€ audio/                 # Audio files for this episode
â”‚   â”‚   â”‚   â””â”€â”€ transcript/            # Transcript files for this episode
â”‚   â”‚   â””â”€â”€ example2/                  # Example: audio and transcipt data
â”‚   â”‚       â”œâ”€â”€ audio/                 # Audio files for this episode
â”‚   â”‚       â””â”€â”€ transcript/            # Transcript files for this episode
â”‚   â””â”€â”€ processed_data/                # Merged training dataset
â”‚       â”œâ”€â”€ train/                     # Training set
â”‚       â”œâ”€â”€ validation/                # Validation set
â”‚       â”œâ”€â”€ test/                      # Test set
â”‚       â””â”€â”€ dataset_dict.json          # Dataset configuration file
â”œâ”€â”€ ğŸ“‚ configs/                        # Configuration files
â”‚   â””â”€â”€ training_config.yaml           # Training configuration file
â”œâ”€â”€ ğŸ“‚ logs/                           # Logs and experiment records
â”‚   â”œâ”€â”€ training.log                   # Training logs
â”‚   â””â”€â”€ wandb/                         # Weights & Biases experiment records
â”œâ”€â”€ requirements.txt                   # Python dependencies
â””â”€â”€ README.md                          # Project documentation
```

## ğŸš€ Quick Start

**Note**: This repository provides the recommended structure. You need to implement your own scripts and organize your data according to this structure.

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Prepare Data
```bash
# Example commands (implement your own scripts):
python scripts/dataset_processor.py --input_dir data/raw_data --output_dir data/processed_data
```

### 3. Fine-tune Model
```bash
# Example training command (adapt to your setup):
python tts_pipeline.py --stage train --dataset_path ./data/processed_dataset
```

### 4. Generate Speech
```bash
# Example inference command (implement your own pipeline):
python tts_pipeline.py --stage inference --model_path models/finetuned_model--prompt "This is not just voice synthesis â€” it is signal extraction. We began with raw, noisy audio from real-world conversations, meetings, and phone calls, and fine-tuned it into a voice that is clear, responsive, and context-aware." --audio_output generated_audio.wav
```

## ğŸ“‹ Features

- âœ… Multi-language TTS fine-tuning support
- âœ… Weights & Biases experiment tracking integration
- âœ… Accelerate distributed training support
- âœ… Modular data processing pipeline
- âœ… Simplified inference interface

## ğŸ› ï¸ Technical Specifications

- **Base Model**: Orpheus 3B
- **Training Framework**: PyTorch + Transformers + Accelerate
- **Audio Processing**: LibROSA + SoundFile
- **Experiment Tracking**: Weights & Biases



## ğŸ”§ System Requirements

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (GPU recommended)
- At least 16GB RAM
- At least 10GB available disk space

## ğŸ“ Notes

- This repository provides a template structure - you need to implement your own scripts
- Ensure audio quality is good with minimal background noise
- Recommend using at least 10-20 audio samples for fine-tuning
- Training time depends on hardware configuration
- Make sure to set appropriate WANDB API key
- Organize your data according to the suggested folder structure

## ğŸ¤ Contributing

Issue reports and feature requests are welcome!

## ğŸ“š Documentation

For complete usage guide, please refer to: [Project Usage Guide](docs/PROJECT_GUIDE.md)

## ğŸ“„ License

This project is licensed under the MIT License. 